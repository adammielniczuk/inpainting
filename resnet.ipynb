{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.utils.data as dutils\n",
    "from tqdm import tqdm\n",
    "import torchvision.utils as vutils\n",
    "import time\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, FEATURES_G):\n",
    "        super(DownBlock, self).__init__()\n",
    "\n",
    "        self.main=nn.Sequential(\n",
    "            nn.Conv2d(FEATURES_G, FEATURES_G*2, 3, 2, 1),\n",
    "            nn.BatchNorm2d(FEATURES_G*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "    \n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, FEATURES_G):\n",
    "        super(UpBlock, self).__init__()\n",
    "\n",
    "        self.main=nn.Sequential(\n",
    "            nn.ConvTranspose2d(FEATURES_G, int(FEATURES_G/2), 3, 2, 1),\n",
    "            nn.BatchNorm2d(int(FEATURES_G/2)),\n",
    "            nn.ReLU(inplace=True)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "class ResNetGenerator(nn.Module):\n",
    "    def __init__(self, FEATURES_G=32, num_blocks=5):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        self.project = nn.Linear(256, 256**2)\n",
    "        self.FEATURES_G=FEATURES_G\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.initial=nn.Sequential(\n",
    "            nn.Conv2d(4, self.FEATURES_G, 7, 1, 3),\n",
    "            nn.BatchNorm2d(self.FEATURES_G),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        \n",
    "        # Reshape to start the convolution stack\n",
    "     #   self.initial = nn.Sequential(\n",
    "    #        nn.Conv2d(16384, hidden_dim * 8, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "     #       nn.BatchNorm2d(hidden_dim * 8),\n",
    "     #       nn.ReLU(inplace=True)\n",
    "     #   )\n",
    "        self.down=nn.Sequential(\n",
    "            *[DownBlock(self.FEATURES_G*(2**x)) for x in range(5)]\n",
    "        )\n",
    "        self.up=nn.Sequential(\n",
    "            *[UpBlock(self.FEATURES_G*(2**(5-x))) for x in range(5)]\n",
    "        )\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(self.FEATURES_G*32, self.FEATURES_G*32) for _ in range(num_blocks)]\n",
    "        )\n",
    "\n",
    "  \n",
    "\n",
    "        # Output layer\n",
    "        self.out_conv = nn.ConvTranspose2d(self.FEATURES_G, 3, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, noise, x):\n",
    "        b_size = x.shape[0]\n",
    "        cond = self.project(noise)\n",
    "        cond = torch.reshape(cond, (b_size, 1, 256, 256))\n",
    "        x = torch.concat((cond, x), dim=1)\n",
    "\n",
    "       \n",
    "        x = self.initial(x)\n",
    "        x=self.down(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.up(x)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "        x = 0.5*(self.tanh(x)+1)\n",
    "\n",
    "        return x\n",
    "class Dataset(dutils.Dataset):\n",
    "    def __init__(self, transform=None, Test=False):  \n",
    "        self.transform = transform\n",
    "        if Test:\n",
    "            self.folder_path='images/test/'\n",
    "        else:\n",
    "            self.folder_path='images/train/'\n",
    "        self.images = [x for x in os.listdir(self.folder_path) if 'cut' not in x if 'hole' not in x]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\t\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        with Image.open(self.folder_path+image) as img:\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "        return img\n",
    "transform = T.Compose([\n",
    "\tT.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "\tT.ToTensor()\n",
    "])\n",
    "train_ds = Dataset(transform=transform)\n",
    "test_ds = Dataset(transform=transform, Test=True)\n",
    "train = dutils.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test = dutils.DataLoader(test_ds, batch_size=16, shuffle=True)\n",
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\tself.main = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(3, FEATURES_D, 4, 2, 1),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\t\t\t\n",
    "\t\t\tnn.Conv2d(FEATURES_D, FEATURES_D*2, 4, 2, 1),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(FEATURES_D*2, FEATURES_D*4, 4, 2, 1),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(FEATURES_D*4, FEATURES_D*8, 4, 2, 1),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(FEATURES_D*8, FEATURES_D*16, 4, 2, 1),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\t\t\t\n",
    "            nn.Conv2d(FEATURES_D*16,FEATURES_D*32, 4, 2, 1),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(FEATURES_D*32, 1, 4, 1, 0),\n",
    "\t\t\tnn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\treturn self.main(input)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "\t'cuda' if torch.cuda.is_available()\n",
    "\telse 'mps' if torch.backends.mps.is_available()\n",
    "\telse 'cpu'\n",
    ")\n",
    "BATCH_SIZE = 8\n",
    "Z_DIM = 256\n",
    "EPOCHS = 300\n",
    "BETA_1 = 0.5\n",
    "BETA_2 = 0.999\n",
    "LEARNING_RATE = 1e-4\n",
    "FEATURES_D=32\n",
    "IMG_SIZE = 256\n",
    "PATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Started training using device: {device}')\n",
    "\n",
    "generator = ResNetGenerator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "d_opt = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA_1, BETA_2))\n",
    "g_opt = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(BETA_1, BETA_2))\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(16, Z_DIM, device=device)\n",
    "fixed_images = next(iter(train))[:16].to(device)\n",
    "\n",
    "fixed_x_offset = max(0, (IMG_SIZE - PATCH_SIZE) // 2)\n",
    "fixed_y_offset =  fixed_x_offset\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "\tfor image_batch in tqdm(train):\n",
    "\t\timage_batch = image_batch.to(device)\n",
    "\t\tb_size = image_batch.shape[0]\n",
    "\t\tdiscriminator.zero_grad()\n",
    "\n",
    "\t\ty_hat_real = discriminator(image_batch).view(-1)\n",
    "\t\ty_real = torch.ones_like(y_hat_real, device=device)\n",
    "\t\treal_loss = loss_fn(y_hat_real, y_real)\n",
    "\t\treal_loss.backward()\n",
    "\n",
    "\t\n",
    "\n",
    "\t\timage_batch[:, :, fixed_x_offset:fixed_x_offset+PATCH_SIZE, fixed_y_offset:fixed_y_offset+PATCH_SIZE] = 0\n",
    "\n",
    "\t\t# Predict using generator\n",
    "\t\tnoise = torch.randn(b_size, Z_DIM, device=device)\n",
    "\t\tpredicted_patch = generator(noise,image_batch)\n",
    "\n",
    "\t\t# Replace black patch with generator output\n",
    "\t\timage_batch[:, :, fixed_x_offset:fixed_x_offset+PATCH_SIZE, fixed_y_offset:fixed_y_offset+PATCH_SIZE] = predicted_patch[:, :, fixed_x_offset:fixed_x_offset+PATCH_SIZE, fixed_y_offset:fixed_y_offset+PATCH_SIZE]\n",
    "\n",
    "\t\t# Predict fake images using discriminator\n",
    "\t\ty_hat_fake = discriminator(image_batch.detach()).view(-1)\n",
    "\n",
    "\t\t# Train discriminator\n",
    "\t\ty_fake = torch.zeros_like(y_hat_fake)\n",
    "\t\tfake_loss = loss_fn(y_hat_fake, y_fake)\n",
    "\t\tfake_loss.backward()\n",
    "\t\td_opt.step()\n",
    "\n",
    "\t\t# Train generator\n",
    "\t\tgenerator.zero_grad()\n",
    "\t\ty_hat_fake = discriminator(image_batch).view(-1)\n",
    "\t\tg_loss = loss_fn(y_hat_fake, torch.ones_like(y_hat_fake))\n",
    "\t\tg_loss.backward()\n",
    "\t\tg_opt.step()\n",
    "\n",
    "\tfixed_images[:, :, fixed_x_offset:fixed_x_offset+PATCH_SIZE, fixed_y_offset:fixed_y_offset+PATCH_SIZE] = 0\n",
    "\twith torch.no_grad():\n",
    "\t\tpredicted_patches = generator(fixed_noise, fixed_images)\n",
    "\tfixed_images[:, :, fixed_x_offset:fixed_x_offset+PATCH_SIZE, fixed_y_offset:fixed_y_offset+PATCH_SIZE] = predicted_patches[:, :, fixed_x_offset:fixed_x_offset+PATCH_SIZE, fixed_y_offset:fixed_y_offset+PATCH_SIZE]\n",
    "\timg = T.ToPILImage()(vutils.make_grid(fixed_images.to('cpu'), normalize=True, padding=2, nrow=4))\n",
    "\timg.save(f'progress3/epoch_{epoch}.jpg')\n",
    "train_time = time.time() - start\n",
    "print(f'Total training time: {train_time // 60} minutes')\n",
    "\n",
    "generator = generator.to('cpu')\n",
    "\n",
    "\n",
    "torch.save(generator, 'models/resnet_generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=torch.load('models/resnet_generator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_x_offset = max(0, (IMG_SIZE - PATCH_SIZE) // 2)\n",
    "fix_y_offset =  fix_x_offset\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "\timages = next(iter(test))\n",
    "\timages = torch.reshape(images, (16, 3, 256, 256))\n",
    "\n",
    "\timg_og = images.clone()\n",
    "\n",
    "\n",
    "\timages[:, :, fix_x_offset:fix_x_offset+PATCH_SIZE, fix_y_offset:fix_y_offset+PATCH_SIZE] = 0\n",
    "\n",
    "\n",
    "\tnoise = torch.randn(images.shape[0], 256)\n",
    "\twith torch.no_grad():\n",
    "\t\tpredicted_patches = generator(noise, images)\n",
    "\t\n",
    "\timages[:, :, fix_x_offset:fix_x_offset+PATCH_SIZE, fix_y_offset:fix_y_offset+PATCH_SIZE] = predicted_patches[:, :, fix_x_offset:fix_x_offset+PATCH_SIZE, fix_y_offset:fix_y_offset+PATCH_SIZE]\n",
    "\n",
    "\timages.to('cpu')\n",
    "\n",
    "\timg = torch.cat([img_og, images], dim=3)\n",
    "\timg = T.ToPILImage()(vutils.make_grid( img, normalize=True, padding=2, nrow=4))\n",
    "\timg.save(f'test/test_resnet_{i+1}.jpg')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
